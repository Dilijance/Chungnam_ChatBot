{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import glob\n",
    "import os\n",
    "import shutil\n",
    "import time\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "data_path = \"C:\\Git\\Chungnam_ChatBot\\pytorch_main\\data\\Cat_and_dog/train\"\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize([256, 256]),\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "train_dataset = torchvision.datasets.ImageFolder(\n",
    "    data_path,\n",
    "    transform=transform,\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "\n",
    "print(len(train_dataset))\n",
    "\n",
    "# samples, labels = train_loader._get_iterator()._next_data()\n",
    "# classes = {0: \"cat\", 1: \"dog\"}\n",
    "# fig = plt.figure(figsize=(16, 24))\n",
    "# for i in range(24):\n",
    "#     fig.add_subplot(4, 6, i + 1)\n",
    "#     plt.title(classes[labels[i].item()])\n",
    "#     plt.axis(\"off\")\n",
    "#     plt.imshow(np.transpose(samples[i].numpy(), (1, 2, 0)))\n",
    "# plt.subplots_adjust(bottom=0.2, top=0.6, hspace=0)\n",
    "# plt.show()\n",
    "\n",
    "resnet18 = models.resnet18(pretrained=True)\n",
    "\n",
    "\n",
    "def set_parameter_requires_grad(model, feature_extracting=True):\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "\n",
    "set_parameter_requires_grad(resnet18)\n",
    "resnet18.fc = nn.Linear(512, 1)\n",
    "\n",
    "for name, param in resnet18.named_parameters():\n",
    "    print(name)\n",
    "print(\"requires_grad 가 True 인 layer:-----------\")\n",
    "for name, param in resnet18.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name)\n",
    "\n",
    "model = models.resnet18(pretrained=True)\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "model.fc = torch.nn.Linear(512, 2)\n",
    "for param in model.fc.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "optimizer = torch.optim.Adam(model.fc.parameters())\n",
    "cost = torch.nn.CrossEntropyLoss()\n",
    "print(model)\n",
    "\n",
    "\n",
    "def train_model(\n",
    "    model, dataloaders, criterion, optimizer, device, num_epochs=13, is_train=True\n",
    "):\n",
    "    since = time.time()\n",
    "    acc_history = []\n",
    "    loss_history = []\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"Epoch {epoch}/{num_epochs-1}\")\n",
    "        # print('----------')\n",
    "        print(\"-\" * 10)\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "\n",
    "        for inputs, labels in dataloaders:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            model.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "        epoch_loss = running_loss / len(dataloaders.dataset)\n",
    "        epoch_acc = running_corrects.double() / len(dataloaders.dataset)\n",
    "\n",
    "        print(f\"Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}\")\n",
    "\n",
    "        if epoch_acc > best_acc:\n",
    "            best_acc = epoch_acc\n",
    "\n",
    "        acc_history.append(epoch_acc.item())\n",
    "        loss_history.append(epoch_loss)\n",
    "        torch.save(\n",
    "            model.state.dict(), os.path.join(data_path, \"0:0=2d.pth\".format(epoch))\n",
    "        )\n",
    "        print()\n",
    "    time_elapsed = time.time() - since\n",
    "    print(f\"Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s\")\n",
    "    print(f\"Best Acc: {best_acc:4f}\")\n",
    "    return acc_history, loss_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_to_update = []\n",
    "for name, param in resnet18.named_parameters():\n",
    "    if param.requires_grad == True:\n",
    "        params_to_update.append(param)\n",
    "        print(\"\\t\", name)\n",
    "\n",
    "optimizer = optim.Adam(params_to_update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "train_acc_hist, train_loss_hist = train_model(resnet18, train_loader, criterion, optimizer, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model, dataloaders, device):\n",
    "    since = time.time()\n",
    "    acc_history = []\n",
    "    best_acc = 0.0\n",
    "\n",
    "    saved_models = glob.glob(r\"C:/Git/Chungnam_ChatBot/pytorch_main/data/Cat_and_dog/train/\" + \"*.pth\")\n",
    "    saved_models.sort()\n",
    "\n",
    "    for model_path in saved_models:\n",
    "        print('Loading model', model_path)\n",
    "        model.load_state_dict(torch.load(model_path))\n",
    "        model.eval()\n",
    "        model.to(device)\n",
    "        running_corrects = 0\n",
    "\n",
    "        for inputs, labels in dataloaders:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            with torch.inference():\n",
    "                outputs = model(inputs)\n",
    "\n",
    "            _, preds = torch.max(outputs.data, 1)\n",
    "            preds[preds >= 0.5] = 1\n",
    "            preds[preds < 0.5] = 0\n",
    "            running_corrects += preds.eq(labels.cpu()).int().sum()\n",
    "\n",
    "        epoch_acc = running_corrects.double()/len(dataloaders.dataset)\n",
    "        print(f\"Acc: {epoch_acc: .4f}\")\n",
    "        if epoch_acc > best_acc:\n",
    "            best_acc = epoch_acc\n",
    "        acc_history.append(epoch_acc.item())\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print(f\"Validation complete in {time_elapsed//60:.0f}, {time_elapsed//60:.0f}\")\n",
    "\n",
    "\n",
    "\n",
    "    plt.plot"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
